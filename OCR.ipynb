{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16Hg8qMy-3XG9zhdkS6ENXiZ9eV07oJKt",
      "authorship_tag": "ABX9TyOiY7VaZryTBjSrRKOnbhuj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/partho2001/OCR_/blob/main/OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qt7ZYYkPviHk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d72a328-6b2f-43a2-84a4-e60eceeb0dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing image /content/OCR/iam_words/words/r06/r06-022/r06-022-03-05.png: cannot identify image file '/content/OCR/iam_words/words/r06/r06-022/r06-022-03-05.png'\n",
            "Error processing image /content/OCR/iam_words/words/r06/r06-022/r06-022-03-05.png: cannot identify image file '/content/OCR/iam_words/words/r06/r06-022/r06-022-03-05.png'\n",
            "92255 92255\n",
            "Epoch 1/10\n",
            "2307/2307 [==============================] - 448s 194ms/step - loss: 3.8134 - accuracy: 0.1165 - val_loss: 3.6128 - val_accuracy: 0.1406\n",
            "Epoch 2/10\n",
            "2307/2307 [==============================] - 411s 178ms/step - loss: 3.4695 - accuracy: 0.1626 - val_loss: 3.4111 - val_accuracy: 0.1742\n",
            "Epoch 3/10\n",
            "2307/2307 [==============================] - 433s 188ms/step - loss: 3.2354 - accuracy: 0.2092 - val_loss: 3.3217 - val_accuracy: 0.1969\n",
            "Epoch 4/10\n",
            "2307/2307 [==============================] - 433s 188ms/step - loss: 3.0220 - accuracy: 0.2526 - val_loss: 3.2551 - val_accuracy: 0.2153\n",
            "Epoch 5/10\n",
            "2307/2307 [==============================] - 429s 186ms/step - loss: 2.8257 - accuracy: 0.2912 - val_loss: 3.2107 - val_accuracy: 0.2262\n",
            "Epoch 6/10\n",
            "2307/2307 [==============================] - 445s 193ms/step - loss: 2.6317 - accuracy: 0.3316 - val_loss: 3.2387 - val_accuracy: 0.2250\n",
            "Epoch 7/10\n",
            "2307/2307 [==============================] - 433s 188ms/step - loss: 2.4458 - accuracy: 0.3695 - val_loss: 3.2695 - val_accuracy: 0.2340\n",
            "Epoch 8/10\n",
            "2307/2307 [==============================] - 431s 187ms/step - loss: 2.2775 - accuracy: 0.4060 - val_loss: 3.3668 - val_accuracy: 0.2209\n",
            "Epoch 9/10\n",
            "2307/2307 [==============================] - 413s 179ms/step - loss: 2.1151 - accuracy: 0.4418 - val_loss: 3.4877 - val_accuracy: 0.2230\n",
            "Epoch 10/10\n",
            "2307/2307 [==============================] - 420s 182ms/step - loss: 1.9670 - accuracy: 0.4773 - val_loss: 3.5879 - val_accuracy: 0.2325\n",
            "577/577 [==============================] - 28s 49ms/step\n",
            "Accuracy on the test set: 23.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from PIL import Image\n",
        "\n",
        "# Load IAM dataset (replace 'path_to_iam_dataset' with the actual path)\n",
        "def load_iam_dataset(dataset_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for root, dirs, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            if file.endswith(\".png\"):\n",
        "                img_path = os.path.join(root, file)\n",
        "                # Assuming the IAM dataset folder structure, where the label is the second-to-last directory\n",
        "                label = os.path.basename(os.path.dirname(root))\n",
        "                images.append(img_path)\n",
        "                labels.append(label)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "dataset_path = '/content/OCR/iam_words'\n",
        "images, labels = load_iam_dataset(dataset_path)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    try:\n",
        "        img = Image.open(img_path).convert('L')  # Open the image and convert to grayscale\n",
        "        img = img.resize((64, 64))  # Resize for a better CNN input size\n",
        "        img_array = img_to_array(img) / 255.0\n",
        "        return img_array\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {img_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Filter out None entries (failed to load images)\n",
        "X_train = np.array([preprocess_image(img_path) for img_path in train_images if preprocess_image(img_path) is not None])\n",
        "y_train = np.array([label for img_path, label in zip(train_images, train_labels) if preprocess_image(img_path) is not None])\n",
        "\n",
        "print(len(X_train), len(y_train))  # Print debug information\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "\n",
        "# Split the dataset into training and testing sets for evaluation\n",
        "X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(X_train, y_train_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a better CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(np.unique(y_train_encoded)), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train_encoded, epochs=10, validation_data=(X_test, y_test_encoded))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_encoded = np.argmax(model.predict(X_test), axis=1)\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
        "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('iam_ocr_model_better_cnn.h5')\n"
      ]
    }
  ]
}